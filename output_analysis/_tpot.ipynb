{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T13:40:05.166607Z",
     "start_time": "2023-05-12T13:40:05.157797Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import graphviz\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T13:40:05.362026Z",
     "start_time": "2023-05-12T13:40:05.320588Z"
    }
   },
   "outputs": [],
   "source": [
    "kc1 = \"/home/hadi/PycharmProjects/Master-Thesis/automl_outputs/gpuserver/tpot/tpot-ds_kc1-seed_662873\"\n",
    "# aps = \"/home/hadi/PycharmProjects/Master-Thesis/automl_outputs/gpuserver/tpot/tpot-ds_APSFailure-seed_662873\"\n",
    "gas = \"/home/hadi/PycharmProjects/Master-Thesis/automl_outputs/gpuserver/tpot/tpot-ds_gas-drift-seed_662873\"\n",
    "electricity = \"/home/hadi/PycharmProjects/Master-Thesis/automl_outputs/gpuserver/tpot/tpot-ds_electricity-seed_662873\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T13:40:05.518116Z",
     "start_time": "2023-05-12T13:40:05.475019Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pops(run_dir: str) -> list:\n",
    "    \"\"\"Reads the pickle of each saved population and returns a list of all populations\n",
    "    run_dir is a string path of a tpot run dir\n",
    "    \"\"\"\n",
    "    pops = []\n",
    "    pops_dir = os.path.join(run_dir, \"pops\")\n",
    "    for p in os.listdir(pops_dir):\n",
    "        p = os.path.join(pops_dir, p)\n",
    "        if not os.path.isdir(p):\n",
    "\n",
    "            with open(p, \"rb\") as in_file:\n",
    "                pops.append(pickle.load(in_file))\n",
    "\n",
    "    return pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T13:40:05.654593Z",
     "start_time": "2023-05-12T13:40:05.610069Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_components_only(indiv_dict: dict, hp_sep: str =\"__\")-> (dict, int) :\n",
    "    \"\"\"\n",
    "    Filters the dictionary of pipeline and returns a dictionary with components only (no HPs). HPs are seperated usually by __\n",
    "\n",
    "    :param indiv_dict: dict of a single pipeline\n",
    "    :param hp_sep: str; how hyperparameters can be identified\n",
    "    :return: filtered dict, int number of combine_dfs in pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    # def filter_func(pair):\n",
    "    #     k, v = pair\n",
    "    #\n",
    "    #     if hp_sep not in v:\n",
    "    #         return True\n",
    "    #     else:\n",
    "    #         return False\n",
    "\n",
    "\n",
    "    filtered_indiv_dict = indiv_dict.copy()\n",
    "    observed = {}\n",
    "\n",
    "    for k, v in indiv_dict.items():\n",
    "        if hp_sep in v:\n",
    "            filtered_indiv_dict.pop(k)\n",
    "        else:\n",
    "            if v not in observed:\n",
    "                observed[v] = 1\n",
    "            else:\n",
    "                observed[v] = observed[v] +1\n",
    "                filtered_indiv_dict[k] = f\"{v} {observed[v]}\"\n",
    "\n",
    "    def combine_ds_exists(pair):\n",
    "        k, v = pair\n",
    "\n",
    "        if \"CombineDFs\" in v:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return filtered_indiv_dict,  len(dict(filter(combine_ds_exists, filtered_indiv_dict.items())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T13:40:05.774088Z",
     "start_time": "2023-05-12T13:40:05.730757Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_named_component_edges(components_dict: dict, all_edges: list) -> list:\n",
    "    \"\"\"\n",
    "    substitutes the component number with its name\n",
    "    :param components_dict: filtered dict from get_components_only()\n",
    "    :param all_edges: list of tuples of pipeline edges\n",
    "    :return: list of lists of named edges\n",
    "    \"\"\"\n",
    "\n",
    "    component_keys = list(components_dict.keys())\n",
    "\n",
    "    # filter out the hyperparameters\n",
    "    def not_hyperparameter(edge_tuple):\n",
    "        if (edge_tuple[0] in component_keys) and (edge_tuple[1] in component_keys):\n",
    "            return True\n",
    "\n",
    "    component_edges = list((filter(not_hyperparameter, all_edges)))\n",
    "\n",
    "    # return component name instead of number\n",
    "    def map_component_names(edge_tuple):\n",
    "        return [components_dict[edge_tuple[1]], components_dict[edge_tuple[0]]]\n",
    "\n",
    "\n",
    "    named_component_edges = list((map(map_component_names, component_edges)))\n",
    "\n",
    "    return list(reversed(named_component_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T13:40:06.245877Z",
     "start_time": "2023-05-12T13:40:06.203521Z"
    }
   },
   "outputs": [],
   "source": [
    "def rename_input_matrix(component_edges: list) -> list:\n",
    "    \"\"\"\n",
    "    Renames input_matrix to \"Input Data\"  or \"Input Data Copy\". if more than one CombineDFs is observed, they will be numbered.\n",
    "\n",
    "    :param component_edges: list of lists of named edges from get_named_component_edges()\n",
    "    :param combine_dfs: integer indicating the number of combine_dfs in the pipeline\n",
    "    :return: list of lists of edges with input_matrix changed to \"Input Data\" or \"Input Data Copy (i)\"\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def rename_single(edge):\n",
    "        if \"input_matrix\" in edge[0]:\n",
    "            if edge[0][-1].isdigit():\n",
    "                edge[0] = f\"Input Data {edge[0][-1]}\"\n",
    "            else:\n",
    "                edge[0] = \"Input Data\"\n",
    "\n",
    "        if \"input_matrix\" in edge[1]:\n",
    "            if edge[1][-1].isdigit():\n",
    "                edge[1] = f\"Input Data {edge[1][-1]}\"\n",
    "            else:\n",
    "                edge[1] = \"Input Data\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return edge\n",
    "\n",
    "    return list(map(rename_single, component_edges))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T13:40:06.446060Z",
     "start_time": "2023-05-12T13:40:06.400478Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_raw_components(component_edges: list) -> list:\n",
    "    \"\"\"\n",
    "    returns unique and ordered component names. Only when we have one CombineDFs!\n",
    "\n",
    "    :param component_edges: list of lists of named edges rename_input_matrix()\n",
    "    :return: list of unique component names\n",
    "    \"\"\"\n",
    "\n",
    "    raw = []\n",
    "    for e in component_edges:\n",
    "        component = e[1]\n",
    "        if component not in raw:\n",
    "            raw.append(component)\n",
    "\n",
    "    return  raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T15:02:47.924989Z",
     "start_time": "2023-05-12T15:02:47.896059Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(edges: list, out_name: str , save_dir: str = None, graph_attrs: dict=None, view: bool = False, format=\"pdf\") -> graphviz.Digraph:\n",
    "    if graph_attrs is None:\n",
    "        graph_attr= {'rankdir':'LR'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dot = graphviz.Digraph(out_name,\n",
    "                      graph_attr=graph_attr)\n",
    "    dot.format = format\n",
    "    dot.edge_attr.update(arrowhead='vee', arrowsize='1.4')\n",
    "\n",
    "    nodes = itertools.chain(*edges)\n",
    "    for n in nodes:\n",
    "        if \"Input Data\" in n:\n",
    "            dot.node(n,  shape=\"cylinder\", height=\"1.1\")\n",
    "        else:\n",
    "            dot.node(n, height = \"1.1\")\n",
    "\n",
    "    dot.edges(edges)\n",
    "\n",
    "\n",
    "    dot.render(directory=save_dir, view=view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T15:02:48.454189Z",
     "start_time": "2023-05-12T15:02:48.453943Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_component_type_counts(raw_coponents: list) -> (list, list, list):\n",
    "    \"\"\"\n",
    "    Returns the coomponents of a pipeline based on their types; classifier, preprocessor, selector\n",
    "\n",
    "    :param raw_coponents: list of pipeline components\n",
    "    :return: list of classifiers, list of preprocessors, list of selectors\n",
    "    \"\"\"\n",
    "    cls_list = [\n",
    "        'GaussianNB',\n",
    "         'BernoulliNB',\n",
    "         'MultinomialNB',\n",
    "         'DecisionTreeClassifier',\n",
    "         'ExtraTreesClassifier',\n",
    "         'RandomForestClassifier',\n",
    "         'GradientBoostingClassifier',\n",
    "         'KNeighborsClassifier',\n",
    "         'LinearSVC',\n",
    "         'LogisticRegression',\n",
    "         'XGBClassifier',\n",
    "         'SGDClassifier',\n",
    "         'MLPClassifier'\n",
    "    ]\n",
    "\n",
    "    preproc_list= [\n",
    "        'Binarizer',\n",
    "        'FastICA',\n",
    "        'FeatureAgglomeration',\n",
    "        'MaxAbsScaler',\n",
    "        'MiMaxScaler',\n",
    "        'Normalizer',\n",
    "        'Nystroem',\n",
    "        'PCA',\n",
    "        'PolynomialFeatures',\n",
    "        'RBFSampler',\n",
    "        'RobustScaler',\n",
    "        'StandardScaler',\n",
    "        'ZeroCount',\n",
    "        'OneHotEncoder'\n",
    "    ]\n",
    "\n",
    "    selectors_list = [\n",
    "        'SelectFwe',\n",
    "        'SelectPercentile',\n",
    "        'VarianceThreshold',\n",
    "        'RFE',\n",
    "        'SelectFromModel'\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cls = list(filter(lambda x: x in cls_list, raw_coponents))\n",
    "    preproc = list(filter(lambda x: x in preproc_list, raw_coponents))\n",
    "    selectors = list(filter(lambda x: x in selectors_list, raw_coponents))\n",
    "\n",
    "\n",
    "    return cls, preproc, selectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T15:02:48.874043Z",
     "start_time": "2023-05-12T15:02:48.833297Z"
    }
   },
   "outputs": [],
   "source": [
    "def combinedfs_with_input_matrix_count(edges: list) -> list:\n",
    "\n",
    "    combine_dfs_edges = list(filter(lambda x: (\"Input Data\" in x[0]) and (\"CombineDFs\" in x[1]), edges))\n",
    "\n",
    "    return len(combine_dfs_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T15:02:49.262744Z",
     "start_time": "2023-05-12T15:02:49.207073Z"
    }
   },
   "outputs": [],
   "source": [
    "def summerize_and_visualize_run(run_dir, save_graph_as=\"pdf\"):\n",
    "    pops = get_pops(run_dir)\n",
    "\n",
    "\n",
    "    stats = {\n",
    "        \"pop\":[],\n",
    "        \"indv\": [],\n",
    "        \"n_comp\":[],\n",
    "        \"n_combinedfs\":[],\n",
    "        \"score\":[],\n",
    "        \"pipeline\":[],\n",
    "        \"clfs\": [],\n",
    "        \"preproc\": [],\n",
    "        \"selectors\":[],\n",
    "        \"n_combine_df_with_input_matrix\":[]\n",
    "    }\n",
    "\n",
    "    for ix_p, p in enumerate(pops):\n",
    "        save_dir = os.path.join(os.path.join(kc1, \"pops\"), str(ix_p))\n",
    "\n",
    "        for ix_indv, indv in enumerate(p):\n",
    "            stats[\"pop\"].append(ix_p)\n",
    "            stats[\"indv\"].append(ix_indv)\n",
    "\n",
    "\n",
    "            components_dict, combine_dfs  = get_components_only(indv[0][2])\n",
    "            component_edges = get_named_component_edges(components_dict, indv[0][1])\n",
    "            component_edges = rename_input_matrix(component_edges)\n",
    "            raw_components = get_raw_components(component_edges)\n",
    "            visualize(edges = component_edges, out_name=f\"{ix_p}_{ix_indv}\",save_dir=save_dir, format=save_graph_as)\n",
    "\n",
    "            cls, preproc, selectors = get_component_type_counts(raw_components)\n",
    "            stats[\"n_combine_df_with_input_matrix\"].append(combinedfs_with_input_matrix_count(component_edges))\n",
    "\n",
    "\n",
    "            stats[\"n_comp\"].append(len(raw_components))\n",
    "            stats[\"n_combinedfs\"].append(combine_dfs)\n",
    "            stats[\"score\"].append(indv[1][1])\n",
    "            stats[\"pipeline\"].append(raw_components)\n",
    "\n",
    "            stats[\"clfs\"].append(cls)\n",
    "            stats[\"preproc\"].append(preproc)\n",
    "            stats[\"selectors\"].append(selectors)\n",
    "\n",
    "\n",
    "    stats_df = pd.DataFrame.from_dict(stats)\n",
    "\n",
    "    stats_df[\"n_preproc\"] = stats_df[\"preproc\"].map(lambda x: len(x))\n",
    "    stats_df[\"n_selectors\"] = stats_df[\"selectors\"].map(lambda x: len(x))\n",
    "    stats_df[\"n_stacking_est\"] = stats_df[\"clfs\"].map(lambda x: 0 if len(x) == 1 else (len(x) -1 if len(x) > 0 else None))\n",
    "\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T15:03:20.432880Z",
     "start_time": "2023-05-12T15:02:50.300777Z"
    }
   },
   "outputs": [],
   "source": [
    "kc1_stats = summerize_and_visualize_run(kc1, \"png\")\n",
    "\n",
    "kc1_stats[(kc1_stats[\"n_combinedfs\"] > 0) & (kc1_stats[\"n_combine_df_with_input_matrix\"] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T14:45:49.102007Z",
     "start_time": "2023-05-12T14:45:49.056552Z"
    }
   },
   "outputs": [],
   "source": [
    "kc1_stats[(kc1_stats[\"n_combinedfs\"] > 0) & (kc1_stats[\"n_combine_df_with_input_matrix\"] == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T14:23:21.557721Z",
     "start_time": "2023-05-12T14:23:21.550064Z"
    }
   },
   "outputs": [],
   "source": [
    "kc1_stats[(kc1_stats[\"n_combinedfs\"] > 0) & (kc1_stats[\"n_combine_df_with_input_matrix\"] == 2)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T14:23:29.849168Z",
     "start_time": "2023-05-12T14:23:29.841287Z"
    }
   },
   "outputs": [],
   "source": [
    "kc1_stats[(kc1_stats[\"n_combinedfs\"] > 0) & (kc1_stats[\"n_combine_df_with_input_matrix\"] == 3)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T14:20:26.576069Z",
     "start_time": "2023-05-12T14:20:26.566375Z"
    }
   },
   "outputs": [],
   "source": [
    "kc1_stats[kc1_stats[\"n_combine_df_with_input_matrix\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T14:16:51.767343Z",
     "start_time": "2023-05-12T14:16:51.710039Z"
    }
   },
   "outputs": [],
   "source": [
    "electricity_stats[electricity_stats[\"n_combinedfs\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T14:08:01.442126Z",
     "start_time": "2023-05-12T14:08:01.441963Z"
    }
   },
   "outputs": [],
   "source": [
    "gas_stats = summerize_and_visualize_run(gas, \"png\")\n",
    "electricity_stats = summerize_and_visualize_run(electricity, \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T14:01:25.006275Z",
     "start_time": "2023-05-12T14:01:24.966758Z"
    }
   },
   "outputs": [],
   "source": [
    "gas_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T13:52:09.718230Z",
     "start_time": "2023-05-12T13:52:09.674556Z"
    }
   },
   "outputs": [],
   "source": [
    "electricity_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T14:01:45.553573Z",
     "start_time": "2023-05-12T14:01:45.503788Z"
    }
   },
   "outputs": [],
   "source": [
    "electricity_stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
