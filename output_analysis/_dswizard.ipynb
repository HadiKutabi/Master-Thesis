{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T17:59:29.926154Z",
     "start_time": "2023-05-12T17:59:29.884576Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import graphviz\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T17:59:30.334062Z",
     "start_time": "2023-05-12T17:59:30.291293Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_deserialize_json(run_dir: str, file_name:str)-> list:\n",
    "    \"\"\"\n",
    "    Loads each pipeline from \"structures.json\" and returns them as a list of dictionaries\n",
    "    :param run_dir: str run directory\n",
    "    :param file_name: str json file name\n",
    "    :return: list of dictionaries (pipelines)\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for line in open(os.path.join(run_dir, f\"{file_name}.json\"), \"r\"):\n",
    "        lines.append(json.loads(line))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T17:59:30.542049Z",
     "start_time": "2023-05-12T17:59:30.501477Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_pipelines(pipelines_list: list) -> list:\n",
    "    \"\"\"\n",
    "    C\n",
    "    :param pipelines_list:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #\n",
    "    pipelines = []\n",
    "\n",
    "    for p in pipelines_list:\n",
    "        steps = p[\"pipeline\"][\"args\"][\"steps\"]\n",
    "        pipe = []\n",
    "        for s in steps:\n",
    "            pipe.append(s[1][\"clazz\"])\n",
    "        pipelines.append(pipe)\n",
    "\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T17:59:30.773873Z",
     "start_time": "2023-05-12T17:59:30.731649Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preproc  ={\n",
    "    \"ImputationComponent\": \"Imputation\",\n",
    "    \"KNNImputerComponent\": \"KNNImputation\",\n",
    "    \"MaxAbsScalerComponent\": \"MaxAbsScaler\",\n",
    "    \"MinMaxScalerComponent\": \"MinMaxScaler\",\n",
    "    \"NormalizerComponent\": \"Normalizer\",\n",
    "    \"QuantileTransformerComponent\": \"QuantileTransformer\",\n",
    "    \"RobustScalerComponent\": \"RobustScaler\",\n",
    "    \"StandardScalerComponent\":\"StandardScaler\"\n",
    "}\n",
    "\n",
    "feat_preproc = {\n",
    "    \"BernoulliRBM\": \"BernoulliRBM\",\n",
    "    \"BinarizerComponent\": \"Binarizer\",\n",
    "    \"FactorAnalysisComponent\": \"FactorAnalysis\",\n",
    "    \"FastICAComponent\": \"FastICA\",\n",
    "    \"FeatureAgglomerationComponent\": \"FeatureAgglomeration\",\n",
    "    \"GenericUnivariateSelectComponent\":\"GenericUnivariateSelect\",\n",
    "    \"KBinsDiscretizer\": \"KBinsDiscretizer\",\n",
    "    \"KernelPCAComponent\": \"KernelPCA\",\n",
    "    \"MissingIndicatorComponent\": \"MissingIndicator\",\n",
    "    \"OneHotEncoderComponent\": \"OneHotEncoder\",\n",
    "    \"OrdinalEncoderComponent\": \"OrdinalEncoder\",\n",
    "    \"PCAComponent\": \"PCA\",\n",
    "    \"PolynomialFeaturesComponent\": \"PolynomialFeatures\",\n",
    "    \"RandomTreesEmbeddingComponent\": \"RandomTreesEmbedding\",\n",
    "    \"SelectKBestComponent\": \"SelectKBest\",\n",
    "    \"SelectPercentileClassification\": \"SelectPercentile\",\n",
    "    \"TruncatedSVDComponent\": \"TruncatedSVD\",\n",
    "    \"VarianceThresholdComponent\": \"VarianceThreshold\"\n",
    "}\n",
    "\n",
    "clfs = {\n",
    "    \"AdaBoostingClassifier\": \"AdaBoostingClassifier\",\n",
    "    \"BernoulliNB\": \"BernoulliNB\",\n",
    "    \"DecisionTree\": \"DecisionTreeClassifier\",\n",
    "    \"GradientBoostingClassifier\": \"GradientBoostingClassifier\",\n",
    "    \"LibSVM_SVC\": \"SVC\",\n",
    "    \"LinearDiscriminantAnalysis\": \"LinearDiscriminantAnalysis\",\n",
    "    \"MultinomialNB\": \"MultinomialNB\",\n",
    "    \"RandomForest\": \"RandomForestClassifier\",\n",
    "    \"SGDClassifier\": \"SGDClassifier\"\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T17:59:30.930068Z",
     "start_time": "2023-05-12T17:59:30.886472Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_component_names(pipelines: list,\n",
    "                        data_preproc: dict = data_preproc,\n",
    "                        feat_preproc: dict = feat_preproc,\n",
    "                        clfs: dict = clfs) -> list:\n",
    "\n",
    "    \"\"\"\n",
    "    changes the names of each pipeline component accoring to data_preproc, feat_preproc, clfs\n",
    "    :param pipelines: list of pipelines (each is a list)\n",
    "    :param data_preproc: dict for mapping data preprocessing component names\n",
    "    :param feat_preproc: dict for mapping feature preprocessing component names\n",
    "    :param clfs: dict for mapping classifier names\n",
    "    :return: list of pipelines with mapped names\n",
    "    \"\"\"\n",
    "\n",
    "    def pipeline_mapper(pipeline):\n",
    "\n",
    "        def component_mapper(component):\n",
    "            component = component.split(\".\")\n",
    "            if \"data_preprocessing\" in component:\n",
    "                return data_preproc[component[-1]]\n",
    "            elif \"feature_preprocessing\" in component:\n",
    "                return feat_preproc[component[-1]]\n",
    "            elif \"classification\" in component:\n",
    "                return clfs[component[-1]]\n",
    "\n",
    "        return list(map(component_mapper, pipeline))\n",
    "\n",
    "\n",
    "    return list(map(pipeline_mapper , pipelines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T17:59:31.154038Z",
     "start_time": "2023-05-12T17:59:31.111035Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_edges(pipelines: list) -> list:\n",
    "\n",
    "    def get_edges(pipeline):\n",
    "        p_edges = []\n",
    "        p_edges.append([\"Input Data\", pipeline[0]])\n",
    "        for ix in range(0, len(pipeline)-1):\n",
    "            p_edges.append([pipeline[ix], pipeline[ix+1]])\n",
    "        return p_edges\n",
    "\n",
    "    return list(map(get_edges , pipelines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T17:59:31.370026Z",
     "start_time": "2023-05-12T17:59:31.325826Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_components_by_type(pipeline: list,\n",
    "                           data_preproc: list = list(data_preproc.values()),\n",
    "                           feat_preproc: list = list(feat_preproc.values()),\n",
    "                           clfs: list = list(clfs.values())\n",
    "                           ) -> (list, list, list):\n",
    "    \"\"\"\n",
    "    Returns the coomponents of a pipeline based on their types; classifier, data preprocessor, feature preprocessor\n",
    "\n",
    "    :param raw_coponents: list of pipeline components\n",
    "    :return: list of classifiers, list of preprocessors, list of selectors\n",
    "\n",
    "    :param pipeline: list of pipeline components\n",
    "    :param data_preproc: list of data preprocessor  names\n",
    "    :param feat_preproc: list of feature preprocessor  names\n",
    "    :param clfs: list of classifier names\n",
    "    :return: list of classifiers, list of data preprocessors, list of feature preprocessors\n",
    "    \"\"\"\n",
    "\n",
    "    classifiers = list(filter(lambda x: x in clfs, pipeline))\n",
    "    data_preproc_components = list(filter(lambda x: x in data_preproc, pipeline))\n",
    "    feature_preproc_components = list(filter(lambda x: x in feat_preproc, pipeline))\n",
    "\n",
    "    return classifiers, data_preproc_components, feature_preproc_components\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T17:59:31.702049Z",
     "start_time": "2023-05-12T17:59:31.659574Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(edges: list, out_name: str ,\n",
    "              save_dir: str = None,\n",
    "              graph_attrs: dict=None,\n",
    "              view: bool = False,\n",
    "              format=\"pdf\") -> graphviz.Digraph:\n",
    "\n",
    "    if graph_attrs is None:\n",
    "        graph_attr= {'rankdir':'LR'}\n",
    "\n",
    "    dot = graphviz.Digraph(out_name,\n",
    "                      graph_attr=graph_attr)\n",
    "    dot.format = format\n",
    "    dot.edge_attr.update(arrowhead='vee', arrowsize='1.4')\n",
    "\n",
    "    nodes = itertools.chain(*edges)\n",
    "    for n in nodes:\n",
    "        if \"Input Data\" in n:\n",
    "            dot.node(n,  shape=\"cylinder\", height=\"1.1\")\n",
    "        else:\n",
    "            dot.node(n, height = \"1.1\")\n",
    "\n",
    "    dot.edges(edges)\n",
    "\n",
    "\n",
    "    dot.render(directory=save_dir, view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T19:30:23.077742Z",
     "start_time": "2023-05-12T19:30:23.019460Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_results_dict(results:list) -> dict:\n",
    "    results_dict = {}\n",
    "    for r in results:\n",
    "        key = str(r[0][1]) + \"-\" + str(r[0][2])\n",
    "        results_dict[key] = r[1:]\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def get_runs_status(results: dict, n_pipelines: int)-> None:\n",
    "\n",
    "    all_runs = []\n",
    "    for i in range(0, n_pipelines):\n",
    "        runs_status = []\n",
    "        n = 0\n",
    "        while results.get(f\"{i}-{n}\"):\n",
    "            run_dict = results.get(f\"{i}-{n}\")[0]\n",
    "            runs_status.append(run_dict[\"status\"])\n",
    "            n+=1\n",
    "        all_runs.append(runs_status)\n",
    "\n",
    "    return all_runs\n",
    "\n",
    "\n",
    "def get_n_sucess_timeout_and_crashed_runs(run_Status:list) -> (list, list, list):\n",
    "    success= []\n",
    "    timeout = []\n",
    "    crashed = []\n",
    "\n",
    "    for p in run_Status:\n",
    "        success.append(\n",
    "            len(list(filter(lambda x: x == \"SUCCESS\", p)))\n",
    "        )\n",
    "        timeout.append(\n",
    "            len(list(filter(lambda x: x == \"TIMEOUT\", p)))\n",
    "        )\n",
    "        crashed.append(\n",
    "            len(list(filter(lambda x: x == \"CRASHED\", p)))\n",
    "        )\n",
    "    return success, timeout, crashed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:48:26.659284Z",
     "start_time": "2023-05-12T20:48:26.556567Z"
    }
   },
   "outputs": [],
   "source": [
    "def summerize_and_visualize_run(run_dir, save_graph_as=\"pdf\"):\n",
    "\n",
    "\n",
    "    stats = {\n",
    "        \"n_comp\":[],\n",
    "        # \"default_train_score\":[],\n",
    "        # \"best_optimized_train_score\":[],\n",
    "        \"pipeline\":[],\n",
    "        \"clfs\": [],\n",
    "        \"d_preproc\": [],\n",
    "        \"f_preproc\":[],\n",
    "    }\n",
    "\n",
    "    structs = load_and_deserialize_json(run_dir, \"structures\")\n",
    "    pipelines = create_pipelines(structs)\n",
    "    pipelines = map_component_names(pipelines)\n",
    "    edges = build_edges(pipelines)\n",
    "\n",
    "\n",
    "\n",
    "    print(len(pipelines))\n",
    "    for ix, p in enumerate(pipelines):\n",
    "        stats[\"n_comp\"].append(len(p))\n",
    "        stats[\"pipeline\"].append(p)\n",
    "\n",
    "        classifiers, data_preproc_components, feature_preproc_components = get_components_by_type(p)\n",
    "        stats[\"clfs\"].append(classifiers)\n",
    "        stats[\"d_preproc\"].append(data_preproc_components)\n",
    "        stats[\"f_preproc\"].append(data_preproc_components)\n",
    "\n",
    "        save_dir = os.path.join(run_dir, \"pipeline_vis\")\n",
    "\n",
    "\n",
    "        visualize(edges = edges[ix], out_name=f\"{ix}\",save_dir=save_dir, format=save_graph_as)\n",
    "\n",
    "    results = load_and_deserialize_json(aps, \"results\")\n",
    "    results_dict = get_results_dict(results)\n",
    "    run_status = get_runs_status(results_dict, len(pipelines))\n",
    "    success, timeout, crashed = get_n_sucess_timeout_and_crashed_runs(run_status)\n",
    "\n",
    "\n",
    "    stats_df = pd.DataFrame.from_dict(stats)\n",
    "    stats_df[\"n_d_preproc\"] = stats_df[\"d_preproc\"].map(lambda x: len(x))\n",
    "    stats_df[\"n_f_preproc\"] = stats_df[\"f_preproc\"].map(lambda x: len(x))\n",
    "    stats_df[\"n_stacking_est\"] = stats_df[\"clfs\"].map(lambda x: 0 if len(x) == 1 else (len(x) -1 if len(x) > 0 else None))\n",
    "\n",
    "    stats_df[\"n_success_runs\"] = success\n",
    "    stats_df[\"n_crashed_runs\"] = crashed\n",
    "    stats_df[\"n_timeout_runs\"] = timeout\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APSFailure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T21:02:44.180098Z",
     "start_time": "2023-05-12T21:02:43.838752Z"
    }
   },
   "outputs": [],
   "source": [
    "aps = \"/home/hadi/PycharmProjects/Master-Thesis/automl_outputs/gpuserver/dswizard/dswizard-ds_electricity-seed_662873\"\n",
    "aps_states = summerize_and_visualize_run(aps)\n",
    "aps_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T21:02:44.183013Z",
     "start_time": "2023-05-12T21:02:44.180864Z"
    }
   },
   "outputs": [],
   "source": [
    "aps_states[\"total_runs\"] = aps_states[\"n_crashed_runs\"] + aps_states[\"n_success_runs\"] + aps_states[\"n_timeout_runs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T21:02:46.718077Z",
     "start_time": "2023-05-12T21:02:46.715616Z"
    }
   },
   "outputs": [],
   "source": [
    "aps_states[\"total_runs\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:19.030142Z",
     "start_time": "2023-05-12T20:49:18.984081Z"
    }
   },
   "outputs": [],
   "source": [
    "aps_states[\"n_crashed_runs\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:21.266923Z",
     "start_time": "2023-05-12T20:49:21.265050Z"
    }
   },
   "outputs": [],
   "source": [
    "aps_states[\"n_success_runs\"].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:21.670203Z",
     "start_time": "2023-05-12T20:49:21.669913Z"
    }
   },
   "outputs": [],
   "source": [
    "aps_states[\"n_timeout_runs\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:56:04.927083Z",
     "start_time": "2023-05-12T20:56:04.912427Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/home/hadi/PycharmProjects/Master-Thesis/automl_outputs/gpuserver/dswizard/dswizard-ds_volkert-seed_662873/runhistory_123.json\", \"r\") as infile:\n",
    "    a = json.load(infile)\n",
    "a.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:56:05.286589Z",
     "start_time": "2023-05-12T20:56:05.216223Z"
    }
   },
   "outputs": [],
   "source": [
    "a[\"meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:48.844085Z",
     "start_time": "2023-05-12T20:49:48.841774Z"
    }
   },
   "outputs": [],
   "source": [
    "nn = 0\n",
    "\n",
    "for s in a[\"structures\"]:\n",
    "    nn+= len(s[\"configs\"])\n",
    "\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:49.406043Z",
     "start_time": "2023-05-12T20:49:49.360462Z"
    }
   },
   "outputs": [],
   "source": [
    "len(a[\"structures\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:49.643178Z",
     "start_time": "2023-05-12T20:49:49.641374Z"
    }
   },
   "outputs": [],
   "source": [
    "a[\"explanations\"][\"structures\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:49.901977Z",
     "start_time": "2023-05-12T20:49:49.854183Z"
    }
   },
   "outputs": [],
   "source": [
    "childreen_dicts = a[\"explanations\"][\"structures\"][\"children\"]\n",
    "details = a[\"explanations\"][\"structures\"][\"details\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:50.222294Z",
     "start_time": "2023-05-12T20:49:50.178582Z"
    }
   },
   "outputs": [],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:50:55.226004Z",
     "start_time": "2023-05-12T20:50:55.182387Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "f_msgs = []\n",
    "\n",
    "for d in childreen_dicts:\n",
    "    d = d[\"details\"]\n",
    "    print(d.get(\"00:00\"))\n",
    "\n",
    "    msgs = []\n",
    "\n",
    "    n=0\n",
    "    while d.get(f\"00:0{n}\"):\n",
    "        msgs.append(d.get(f\"00:0{n}\")[\"failure_message\"])\n",
    "        n+=1\n",
    "\n",
    "    n=0\n",
    "    while d.get(f\"00:1{n}\"):\n",
    "        msgs.append(d.get(f\"00:1{n}\")[\"failure_message\"])\n",
    "        n+=1\n",
    "\n",
    "    f_msgs.append(msgs)\n",
    "\n",
    "\n",
    "\n",
    "msgs = []\n",
    "\n",
    "n=0\n",
    "while details.get(f\"00:0{n}\"):\n",
    "    msgs.append(details.get(f\"00:0{n}\")[\"failure_message\"])\n",
    "    n+=1\n",
    "\n",
    "n=0\n",
    "while details.get(f\"00:1{n}\"):\n",
    "    msgs.append(details.get(f\"00:1{n}\")[\"failure_message\"])\n",
    "    n+=1\n",
    "\n",
    "\n",
    "f_msgs.append(msgs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:50:55.522122Z",
     "start_time": "2023-05-12T20:50:55.480969Z"
    }
   },
   "outputs": [],
   "source": [
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:50:55.962154Z",
     "start_time": "2023-05-12T20:50:55.919232Z"
    }
   },
   "outputs": [],
   "source": [
    "f_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:50:56.503132Z",
     "start_time": "2023-05-12T20:50:56.494363Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(itertools.chain(*f_msgs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:50:57.097579Z",
     "start_time": "2023-05-12T20:50:57.094567Z"
    }
   },
   "outputs": [],
   "source": [
    "set(list(itertools.chain(*f_msgs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:52.508210Z",
     "start_time": "2023-05-12T20:49:52.468364Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(filter(lambda x: x is None, list(itertools.chain(*f_msgs)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:52.950510Z",
     "start_time": "2023-05-12T20:49:52.950114Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(filter(lambda x: x == \"Ineffective\", list(itertools.chain(*f_msgs)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:53.141342Z",
     "start_time": "2023-05-12T20:49:53.104012Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(filter(lambda x: x == \"Unvisited\", list(itertools.chain(*f_msgs)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:53.334308Z",
     "start_time": "2023-05-12T20:49:53.333927Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(filter(lambda x: x == \"Missing MF\", list(itertools.chain(*f_msgs)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T20:49:53.586181Z",
     "start_time": "2023-05-12T20:49:53.544187Z"
    }
   },
   "outputs": [],
   "source": [
    "192 + 99  + 17 - 308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
